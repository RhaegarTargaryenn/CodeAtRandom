You are GitHub Copilot. Generate the complete project for the following assignment. Follow each instruction exactly. Build clean, modular, and production-ready code.

ğŸ“Œ PROJECT: Multi-Document Embedding Search Engine With Caching

Build a search engine over 100â€“200 text files. Use Python. Use FastAPI. Use FAISS or cosine similarity. Implement caching, embeddings, vector search, and ranking explanation.

ğŸ“ CREATE THE FOLLOWING FOLDER STRUCTURE
project/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ embedder.py
â”‚   â”œâ”€â”€ cache_manager.py
â”‚   â”œâ”€â”€ search_engine.py
â”‚   â”œâ”€â”€ api.py
â”‚   â”œâ”€â”€ utils.py
â”‚
â”œâ”€â”€ data/   (ignored through .gitignore; will contain raw text files)
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

ğŸ§© TASKS FOR EACH MODULE

Copilot must implement ALL details.

1ï¸âƒ£ embedder.py

Implement:

Class: Embedder

Use: sentence-transformers/all-MiniLM-L6-v2

Functions:

load_model()

embed_text(text: str)

embed_documents(list_of_texts)

Automatically lowercase input text

Return embeddings as NumPy arrays

Should work with GPU if available

2ï¸âƒ£ cache_manager.py

Implement a caching system using SQLite or JSON.

Must store:

{
 "doc_id": "doc_001",
 "embedding": [...],
 "hash": "<sha256_of_text>",
 "updated_at": "<timestamp>"
}


Functions needed:

compute_hash(text)

load_cache()

save_embedding(doc_id, text, embedding)

check_cache(doc_id, text)

If file hash unchanged â†’ return cached embedding

If file changed â†’ return None

get_all_cached_embeddings()

Make caching efficient and modular.

3ï¸âƒ£ search_engine.py

Implement:

Class: SearchEngine

Responsibilities:

A. Load documents

Load all text files from data/

Clean text: lowercase, remove HTML tags, strip spaces

Store metadata: filename, length, hash

B. Embedding + Caching integration

For each document:

Check cache

If changed â†’ regenerate embedding

If unchanged â†’ load embedding

Store everything in:

self.documents

self.embeddings

C. Vector Search options

Copilot must generate BOTH versions:

Option A: FAISS

Use IndexFlatIP

Normalize embeddings

Option B: Cosine Similarity

Use NumPy

Compute similarity via dot product or cosine similarity

D. Ranking Explanation

For each result return:

{
  "doc_id": "",
  "score": "",
  "preview": "",
  "keywords_overlap": ["word1", "word2"],
  "overlap_ratio": "",
  "doc_length": ""
}


Overlap logic:

Extract tokens from query

Extract tokens from doc

Find intersection

Compute ratio = overlap / len(query_tokens)

Preview should return first 150 characters.

4ï¸âƒ£ api.py

Implement a FastAPI app with:

Endpoint:

POST /search


Input:

{
 "query": "example query",
 "top_k": 5
}


Steps:

Embed query

Search using vector index

Return ranked documents + explanation

Format output cleanly

5ï¸âƒ£ main.py

Initialize SearchEngine

Load all docs & embeddings

Load FastAPI from api.py

Run server

6ï¸âƒ£ requirements.txt

Include:

fastapi
uvicorn
sentence-transformers
faiss-cpu
numpy
scikit-learn
python-multipart

7ï¸âƒ£ README.md CONTENT (Copilot should generate it)

README must include:

âœ”ï¸ What the project does
âœ”ï¸ How caching works
âœ”ï¸ How to run embedding generation
âœ”ï¸ How to start FastAPI server
âœ”ï¸ Folder structure
âœ”ï¸ Design choices
âœ”ï¸ Example usage
âœ”ï¸ Sample API request + response

Keep it super clean and professional.

ğŸ“Œ ADDITIONAL RULES FOR COPILOT

Code must be modular and clean.

Add comments in every file.

Use type hints everywhere.

Build the project following production-level structure.

Ensure everything can run with:

python main.py


Do not add unnecessary complexity.

Make the project easy for beginners to understand.

ğŸ¤– Copilot, generate ALL code files completely:

embedder.py

cache_manager.py

search_engine.py

api.py

main.py

requirements.txt

README.md

Provide full content for each file.